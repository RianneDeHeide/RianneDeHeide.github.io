<!DOCTYPE html>
<html>
<body>

<h1>Bayesian statistics (to be renamed to: Mathematical statistics 2)</h1>
<p>Here is all information about the VU course Bayesian statistics, for those who cannot access the VU Canvas (yet).</p>
<p>
Dear Students,<br>
<br>
Welcome to the course "Bayesian statistics"! In fact, the course will cover other paradigms than Bayesianism as well (mainly: Frequentism), and next year it will be renamed to "Mathematical Statistics 2", which reflects the content a bit better.<br>
<br>
We will cover the following topics:<br>
<br>
<ul>
<li>Bayesian inference: basics, priors, point estimation, credible sets, Bernstein-von-Mises</li>
    <li>Hypothesis testing: paradigms, Bayesian ", sequential ", multiple testing (only FWER and FDR)</li>
        <li>Decision theory: basics, risk, admissibility, minimax, Bayes risk and Bayes rules, posterior expected loss and Bayes actions, admissibility of Bayes rules</li>
            <li>Computational methods: MCMC, EM-algorithm</li>
</ul>
<br>
We will use the following book:<br>
<a href="https://www.routledge.com/Statistical-Theory-A-Concise-Introduction/Abramovich-Ritov/p/book/9781032007458">Link to the book.</a><br>
For the hypothesis testing part and computational methods we will use extra material, which will appear on canvas in due time.<br>
<br>
Both the lectures and practicals will be taught by myself:<br>
Dr. Rianne de Heide - https://riannedeheide.github.io/ <br>
At the moment I'm on maternity leave. I will return to work on the 1st of February. Since this is a new course, I still have to develop it, which I will start to do when I return. So more information on the course will appear on Canvas bit by bit from after the 1st of February and during the course. The content of the course is not set in stone, and I aim for an interactive course, so the practicals will not only consist of making exercises, but also presenting them (and other material) to one another. It depends a bit on the number of students what the exact form will be.<br>
<br>
If you have any questions, feel free to e-mail me (but I can't guarantee I'll answer before the 1st of Febuary, which is my first working day after my leave): r.de.heide@vu.nl.
<br>
Best wishes,<br>
Rianne<br>

</p>

<h3>Examination</h3>
<p>
The course has two written exams, a midterm M and a final F. Grades can be obtained between 1.0 and 10.0. In order to pass the course, (M+F)/2 must be at least 5.5.<br>
Bonus points B can be obtained at a maximum of 1.0 points per exam. In order for the bonus points to be added to either M or F, M or F needs to be at least 5.0. M+B and F+B will be maximised at 10.0. Details on how to obtain bonus points will follow.<br>
</p>
 

 <h3>10-minute summaries</h3>
 <p>
Lecture 2 and the following ones (except lecture 7) will start with a 10-minute summary of the previous lecture on the basis of 5 multiple choice quiz questions. You can form groups of 2-3 students (we need 10 groups in total), and enrol yourselves for one of the lectures under "people" here in canvas. The people in the group get 0.1 bonus point. You need to send me the 5 multiple choice questions (4 answers each) before Wednesday 12.00, and I will check them and put them in MentiMeter. Be creative with the wrong answers you come up with! ChatGPT is for example very good at creating plausible but wrong answers to statistical questions. The person with the highest score on the quiz gets 0.1 bonus point too.
</p>
 

 <h3>Lectures/practicals</h3>
 <p>
There will not be "classical" 2x45-minute lectures and 2x45-minute practicals. We will interchange small blocks of theory presentations with small blocks of making exercises. We will also do other things, like programming together, peer reviewing solutions to exercises of other groups of students, presenting (parts of) papers, exercises, and more.
</p>

<h2> Week 1 </h2>
<p> Introduction to statistics with its different paradigms.<br>

Introduction to Bayesian statistics, paragraph 6.1 of the book.</p>
<a href="https://riannedeheide.github.io/ExercisesLecture1.pdf">Exercises</a><br>
<a href="https://riannedeheide.github.io/L1.1.pdf">Lecture part 1</a><br>
<a href="https://riannedeheide.github.io/L1.2.pdf">Lecture part 2</a><br>

<h2> Week 2 </h2>
<p>
Summary by Chiraze, Gijsje and Yanglin (see above for instructions).<br>
<br>
Priors<br>
Types of priors, the origin of priors.<br>
Conjugate priors.<br>
Jeffreys prior.<br>
Paragraph 6.2 of the book.<br>
<br>
To read during the lecure: Preface of Bruno de Finetti to his book Theory of Probability. <a href="https://www.everand.com/read/338056001/Theory-of-Probability-A-critical-introductory-treatment">Link</a><br>
Or <a href="https://riannedeheide.github.io/DeFinetti-preface.pdf">PDF</a><br>"
</p>

<h2> Week 3 </h2>
<p>
Summary by Yoni, Amarantos, and Despoina (see above for instructions).<br>
<br>
Point estimation<br>

Credible sets 1<br>

Paragraphs 6.3 and 6.4 of the book.
</p>

<h2> Week 4 </h2>
<p>
Summary by Arnoud, Etienne and Haitham (see above for instructions).<br>
<br>
Credible sets 2<br>

Bernstein-von-Mises<br>

Paragraphs 6.4 and 6.6 of the book.
</p>

<h2> Week 5 </h2>
<p>
Summary by Ziyan, Nicholas and Vihanga (see above for instructions).<br>
<br>
New topic: <b>Hypothesis testing</b><br>

Different paradigms (among others: Bayesian hypothesis testing)<br>

Any-time valid inference and sequential testing 1<br>

Paragraphs 6.5 and 4.5 of the book and some extra material<br>

</p>

<h2> Week 6 </h2>
<p>
Summary by Sara and Koen (see above for instructions).<br>
<br>
Sequential testing / any-time valid inference part 2<br>

Multiple testing (only FDR and FWER)<br>

Paragraphs 4.5 and 4.6 of the book, and some extra material.<br>

This is the last lecture before the midterm. The midterm will cover all material up to and including this lecture.<br>

</p>
</body>
</html>
